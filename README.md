# ğŸ§  Smart Query: RAG + LLM Wikipedia QA

A lightweight Retrieval-Augmented Generation (RAG) pipeline using FastAPI, Wikipedia, FAISS, Sentence Transformers, and a generative LLM (FLAN-T5) for intelligent question-answering.

## ğŸš€ Features

- ğŸ” Fetches real-time Wikipedia content
- ğŸ”— Chunks and embeds text using `sentence-transformers`
- ğŸ” Retrieves relevant context with FAISS
- ğŸ¤– Answers questions using `google/flan-t5-large`
- ğŸŒ Minimal frontend with TailwindCSS and Dark Mode toggle

## ğŸ–¼ï¸ Preview



https://github.com/user-attachments/assets/2d817d20-e4db-4f96-bd7d-5aa1f8f91bfe



## ğŸ§ª Local Setup

```bash
# Clone the repo
git clone https://github.com/YA-shiKa/smart-query-wikipedia-qa.git
cd smart-query-wikipedia-qa

# Install dependencies
pip install -r requirements.txt

# Run the app
uvicorn app.main:app --reload
Then open http://localhost:8000 in your browser.
```

## âœ¨ Example Query
- Topic: Apple Inc.

- Question: Who is the current CEO of Apple?

## ğŸ“¦ Models Used

- Embedding: sentence-transformers/all-mpnet-base-v2

- QA Model: google/flan-t5-large
